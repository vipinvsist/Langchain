{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02622ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e15b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = WikipediaRetriever(top_k_result=2, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eac0258",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is AI\"\n",
    "docs=retriver.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "611ca9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Artificial intelligence', 'summary': 'Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.\\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., language models and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields. Some companies, such as OpenAI, Google DeepMind and Meta, aim to create artificial general intelligence (AGI)—AI that can complete virtually any cognitive task at least as well as a human.\\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks and deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture. In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom. Generative AI\\'s ability to create and modify content has led to several unintended consequences and harms, which has raised ethical concerns about AI\\'s long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Artificial_intelligence'}, page_content='Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.\\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., language models and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields. Some companies, such as OpenAI, Google DeepMind and Meta, aim to create artificial general intelligence (AGI)—AI that can complete virtually any cognitive task at least as well as a human.\\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks and deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture. In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom. Generative AI\\'s ability to create and modify content has led to several unintended consequences and harms, which has raised ethical concerns about AI\\'s long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\\n\\n\\n== Goals ==\\nThe general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.\\n\\n\\n=== Reasoning and problem-solving ===\\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.\\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow. Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments. Accurate and efficient reasoning is an unsolved problem.\\n\\n\\n=== Knowledge representation ===\\n\\nKnowledge representation and knowledge engineering allow AI programs to answer questions intelligently and make '),\n",
       " Document(metadata={'title': 'Generative artificial intelligence', 'summary': 'Generative artificial intelligence (Generative AI, GenAI, or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.\\nGenerative AI tools have become more common since the AI boom in the 2020s. This boom was made possible by improvements in transformer-based deep neural networks, particularly large language models (LLMs). Major tools include chatbots such as ChatGPT, Copilot, Gemini, Claude, Grok, and DeepSeek; text-to-image models such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video models such as Veo and Sora. Technology companies developing generative AI include OpenAI, xAI, Anthropic, Meta AI, Microsoft, Google, DeepSeek, and Baidu. \\nGenerative AI is used across many industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. The production of generative AI systems requires large scale data centers using specialized chips which require a lot of electricity for processing and water for cooling. \\nGenerative AI has raised many ethical questions and governance challenges as it can be used for cybercrime, or to deceive or manipulate people through fake news or deepfakes. Even if used ethically, it may lead to mass replacement of human jobs. The tools themselves have been criticized as violating intellectual property laws, since they are trained on copyrighted works.  The material and energy intensity of the AI systems has raised concerns about the environmental impact of AI, especially in light of the challenges created by the energy transition.', 'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence'}, page_content='Generative artificial intelligence (Generative AI, GenAI, or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.\\nGenerative AI tools have become more common since the AI boom in the 2020s. This boom was made possible by improvements in transformer-based deep neural networks, particularly large language models (LLMs). Major tools include chatbots such as ChatGPT, Copilot, Gemini, Claude, Grok, and DeepSeek; text-to-image models such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video models such as Veo and Sora. Technology companies developing generative AI include OpenAI, xAI, Anthropic, Meta AI, Microsoft, Google, DeepSeek, and Baidu. \\nGenerative AI is used across many industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. The production of generative AI systems requires large scale data centers using specialized chips which require a lot of electricity for processing and water for cooling. \\nGenerative AI has raised many ethical questions and governance challenges as it can be used for cybercrime, or to deceive or manipulate people through fake news or deepfakes. Even if used ethically, it may lead to mass replacement of human jobs. The tools themselves have been criticized as violating intellectual property laws, since they are trained on copyrighted works.  The material and energy intensity of the AI systems has raised concerns about the environmental impact of AI, especially in light of the challenges created by the energy transition.\\n\\n\\n== History ==\\n\\n\\n=== Early history ===\\nThe first example of an algorithmically generated media is likely the Markov chain. Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906, and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is trained on a text corpus, it can then be used as a probabilistic text generator.\\nComputers were needed to go beyond Markov chains. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.\\nThe terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal. Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use, process plans for manufacturing and decision plans such as in prototype autonomous spacecraft.\\n\\n\\n=== Generative neural networks (2014–2019) ===\\n\\nSince its inception, the field of machine learning has used both discriminative models and generative models to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress, and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models due to the difficulty of generative modeling.\\nIn 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire imag'),\n",
       " Document(metadata={'title': 'AI boom', 'summary': 'The AI boom is an ongoing period of technological progress in the field of artificial intelligence (AI) that started in the late 2010s before gaining international prominence in the 2020s. Examples include generative AI technologies, such as large language models and AI image generators by companies like OpenAI, as well as scientific advances, such as protein folding prediction led by Google DeepMind. This period is sometimes referred to as an AI spring, to contrast it with previous AI winters. As of 2025, ChatGPT is the 5th most visited website globally behind Google, YouTube, Facebook, and Instagram.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/AI_boom'}, page_content='The AI boom is an ongoing period of technological progress in the field of artificial intelligence (AI) that started in the late 2010s before gaining international prominence in the 2020s. Examples include generative AI technologies, such as large language models and AI image generators by companies like OpenAI, as well as scientific advances, such as protein folding prediction led by Google DeepMind. This period is sometimes referred to as an AI spring, to contrast it with previous AI winters. As of 2025, ChatGPT is the 5th most visited website globally behind Google, YouTube, Facebook, and Instagram.\\n\\n\\n== History ==\\n\\nIn 2012, a University of Toronto research team used artificial neural networks and deep learning techniques to lower the error rate below 25% for the first time during the ImageNet challenge for object recognition in computer vision. The event catalyzed the AI boom later that decade, when many alumni of the ImageNet challenge became leaders in the tech industry. In March 2016, AlphaGo beat Lee Sedol in a five-game match, marking the first time a computer Go program had beaten a 9-dan professional without handicap. This match led to significant increase in public interest in AI. The generative AI race began in earnest in 2016 or 2017 following the founding of OpenAI and earlier advances made in graphics processing units (GPUs), the amount and quality of training data, generative adversarial networks, diffusion models and transformer architectures.\\nIn 2018, the Artificial Intelligence Index, an initiative from Stanford University, reported a global explosion of commercial and research efforts in AI. Europe published the largest number of papers in the field that year, followed by China and North America. Technologies such as AlphaFold led to more accurate predictions of protein folding and improved the process of drug development. Economists and lawmakers began to discuss the potential impact of AI more frequently.\\nThe release of ChatGPT in November 2022, a chatbot based on a large language model created by OpenAI, accelerated the pace of AI boom. ChatGPT had over 100 million users in two months, and according to investment bank UBS, was the fastest-growing consumer software application in history. Several other companies have released competitors. At a similar time, text-to-image-models such as DALL-E and Midjourney become popular as a way to generate complicated photo-like illustrations. Speech synthesis software also became able to replicate the voices and speech of specific people.\\n\\n\\n== Advances ==\\n\\n\\n=== Biomedical ===\\nThe AlphaFold 2 score of more than 90 in CASP\\'s global distance test (GDT) is considered a significant achievement in computational biology and great progress towards a decades-old grand challenge of biology. The structural biologist and Nobel Prize winner Venki Ramakrishnan called the result \"a stunning advance on the protein folding problem\", adding that \"It has occurred decades before many people in the field would have predicted.\"\\nThe ability to predict protein structures accurately based on the constituent amino acid sequence is expected to accelerate drug discovery and enable a better understanding of diseases.\\n\\n\\n=== Images and videos ===\\n\\nText-to-image models captured widespread public attention when OpenAI announced DALL-E, a transformer system, in January 2021. A successor capable of generating complex and realistic images, DALL-E 2, was unveiled in April 2022. An alternative text-to-image model, Midjourney, was released in July 2022. Another alternative, open-source model Stable Diffusion, released in August 2022.\\nFollowing other text-to-image models, language model-powered text-to-video platforms such as Runway, OpenAI\\'s Sora, DAMO, Make-A-Video, Imagen Video and Phenaki can generate video from text as well as image prompts.\\n\\n\\n=== Language ===\\nGPT-3 is a large language model that was released in 2020 by OpenAI and is capable of generating high-quality human-like text. The tool has bee')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdf99fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"the role of the AI in the modern world\"\n",
    "\n",
    "docs = retriver.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ecd0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Result1---------\n",
      "Content:\n",
      " AI: The Somnium Files (  EYE) is a 2019 visual novel adventure video game developed and published by Spike Chunsoft. Set in near-future Tokyo, the story follows Kaname Date, a detective who investigates a string of serial killings by entering suspects' memories to extract information. Gameplay is split into two sections: first-person visual novel segments and third-person exploration. The plot progresses via branching routes, leading to multiple endings depending on choices made by the player.\n",
      "The game was written and directed by Zero Escape creator Kotaro Uchikoshi. In contrast to his previous work, Uchikoshi wanted the game to reach a broader audience, and developed it with adventure game fans in mind. Gameplay was simplified, dialogue was reduced, and Yūsuke Kozaki was brought on as lead character designer due to his reputation as a manga artist. The game was first teased in 2017 under the working title Project: Psync, and was formally announced at the 2018 Anime Expo. It released for Nintendo Switch, PlayStation 4, and Windows in September 2019, and Xbox One in September 2021.\n",
      "AI: The Somnium Files was positively received, with praise for its story, art direction, and characters, while some criticized the game's tone and trial-and-error puzzle mechanics. A sequel, AI: The Somnium Files – Nirvana Initiative, was released in 2022.\n",
      "\n",
      "\n",
      "== Gameplay ==\n",
      "\n",
      "AI: The Somnium Files is a single-player adventure video game with visual novel elements, in which the players assume the role of detective Kaname Date. Gameplay is split into two sections: investigating Tokyo and exploring dream worlds, known as \"Somnia\". The story progresses via branching routes, leading to multiple endings depending on choices the player makes. The plot is not fully revealed in a single playthrough; the player must complete every route to gather the information necessary to solve the mystery. Rather than starting from the beginning of the game after each completed route, the player can skip directly to other chapters–called \"Days\"–using an in-game flowchart.\n",
      "Investigation sections take place from a first-person perspective. The player interacts with the environment via an on-screen cursor, similar to point-and-click video games. Date uses his artificial intelligence assistant, Aiba, to analyze crime scenes, reference databases, and receive phone calls. Aiba is also able to augment Date's field of view with optical magnification, X-ray vision, and thermography. Apart from collecting evidence, Date also gathers information via non-player characters in a visual novel format. By selecting characters with the cursor, the player is able to ask questions pertaining to the individual or the environment. During specific action-oriented segments of the game, the player may be presented with quick time events to evade danger or engage in scripted combat sequences.\n",
      "Somnium exploration plays out in third-person. Date uses a device called the \"Psync Machine\" to enter the Somnia of subjects who withhold information from him. Within a subject's Somnium, Aiba acts as Date's avatar, taking on a humanoid form. The player controls Aiba, exploring the dream world and solving puzzles to extract information. Somnium puzzles involve examining objects within the environment and choosing an action to perform with them. The player is only able to remain in Somnia for six minutes, with each object subtracting a set amount of seconds from the timer when interacted with. If the player triggers the correct sequence of objects, a \"Mental Lock\" will open, allowing Aiba to venture further into the subject's subconscious. Depending on the Mental Locks the player chooses to open, the game's story will diverge upon exiting the Somnium.\n",
      "\n",
      "\n",
      "== Synopsis ==\n",
      "\n",
      "\n",
      "=== Setting ===\n",
      "The game takes place in near-future Tokyo, and follows detective Kaname Date of the top-secret police department ABIS (Advanced Brain Investigation Squad). ABIS, led by Boss, investigates crimes through a method called \"Psyncing\", ..\n",
      "--------Result2---------\n",
      "Content:\n",
      " Ai Weiwei (  EYE way-WAY; Chinese: 艾未未; pinyin: Ài Wèiwèi, IPA: [âɪ wêɪ.wêɪ]; born 28 August 1957) is a Chinese contemporary artist, documentarian, and activist. Ai grew up in the far northwest of China, where he lived under harsh conditions due to his father's exile. As an activist, he has been openly critical of the Chinese Government's stance on democracy and human rights. He investigated government corruption and cover-ups, in particular the Sichuan schools corruption scandal following the collapse of \"tofu-dreg schools\" in the 2008 Sichuan earthquake. In April 2011, Ai Weiwei was arrested at Beijing Capital International Airport for \"economic crimes,\" and detained for 81 days without charge. Ai Weiwei emerged as a vital instigator in Chinese cultural development, an architect of Chinese modernism, and one of the nation's most vocal political commentators.\n",
      "Ai Weiwei encapsulates political conviction and poetry in his many sculptures, photographs, and public works. Since being allowed to leave China in 2015, he has lived in Portugal, Germany, and the United Kingdom.\n",
      "\n",
      "\n",
      "== Life ==\n",
      "\n",
      "\n",
      "=== Early life and work ===\n",
      "Ai's father was the Chinese poet Ai Qing, who was denounced during the Anti-Rightist Movement. In 1958, the family was sent to a labour camp in Beidahuang, Heilongjiang, when Ai was one year old. They were subsequently exiled to Shihezi, Xinjiang in 1961, where they lived for 16 years. Upon Mao Zedong's death and the end of the Cultural Revolution, the family returned to Beijing in 1976.\n",
      "Weiwei notes this exile as “the whirlpool that swallowed up my father upended my life too, leaving a mark on me that I carry to this day.”\n",
      "In 1978, Ai enrolled in the Beijing Film Academy and studied animation. In 1978, he was one of the founders of the early avant garde art group the \"Stars\", together with Ma Desheng, Wang Keping, Mao Lizi, Huang Rui, Li Shuang, Ah Cheng and Qu Leilei. The group disbanded in 1983, yet Ai participated in regular Stars group shows, The Stars: Ten Years, 1989 (Hanart Gallery, Hong Kong and Taipei), and a retrospective exhibition in Beijing in 2007: Origin Point (Today Art Museum, Beijing).\n",
      "\n",
      "\n",
      "=== Life in the United States ===\n",
      "\n",
      "From 1981 to 1993, he lived in the United States. He was among the first generation of students to study abroad following China's reform in 1980, being one of the 161 students to take the TOEFL (Test of English as a Foreign Language) in 1981. For the first few years, Ai lived in Philadelphia and San Francisco. He studied English at the University of Pennsylvania and the Berkeley Adult School. Later, he moved to New York City. He studied briefly at Parsons School of Design. Ai attended the Art Students League of New York from 1983 to 1986, where he studied with Bruce Dorfman, Knox Martin and Richard Pousette-Dart. He later dropped out of school and made a living out of drawing street portraits and working odd jobs. During this period, he gained exposure to the works of Marcel Duchamp, Andy Warhol, and Jasper Johns, and began creating conceptual art by altering readymade objects.\n",
      "Ai befriended beat poet Allen Ginsberg while living in New York, following a chance meeting at a poetry reading where Ginsberg read out several poems about China. Ginsberg had traveled to China and met with Ai's father, the noted poet Ai Qing, and consequently Ginsberg and Ai became friends.\n",
      "When he was living in the East Village (from 1983 to 1993), Ai carried a camera with him all the time and would take pictures of his surroundings wherever he was. The resulting collection of photos were later selected and is now known as the New York Photographs. At the same time, Ai became fascinated by blackjack card games and frequented Atlantic City casinos. He is still regarded in gambling circles as a top tier professional blackjack player according to an article published on blackjackchamp.com.\n",
      "\n",
      "\n",
      "=== Return to China ===\n",
      "In 1993, Ai returned to China after his father became ill. He helped establish the experimental a..\n",
      "--------Result3---------\n",
      "Content:\n",
      " The history of artificial intelligence (AI) began in antiquity, with myths, stories, and rumors of artificial beings endowed with intelligence or consciousness by master craftsmen. The study of logic and formal reasoning from antiquity to the present led directly to the invention of the programmable digital computer in the 1940s, a machine based on abstract mathematical reasoning. This device and the ideas behind it inspired scientists to begin discussing the possibility of building an electronic brain.\n",
      "The field of AI research was founded at a workshop held on the campus of Dartmouth College in 1956. Attendees of the workshop became the leaders of AI research for decades. Many of them predicted that machines as intelligent as humans would exist within a generation. The U.S. government provided millions of dollars with the hope of making this vision come true.\n",
      "Eventually, it became obvious that researchers had grossly underestimated the difficulty of this feat. In 1974, criticism from James Lighthill and pressure from the U.S.A. Congress led the U.S. and British Governments to stop funding undirected research into artificial intelligence. Seven years later, a visionary initiative by the Japanese Government and the success of expert systems  reinvigorated investment in AI, and by the late 1980s, the industry had grown into a billion-dollar enterprise. However, investors' enthusiasm waned in the 1990s, and the field was criticized in the press and avoided by industry (a period known as an \"AI winter\"). Nevertheless, research and funding continued to grow under other names.\n",
      "In the early 2000s, machine learning was applied to a wide range of problems in academia and industry. The success was due to the availability of powerful computer hardware, the collection of immense data sets, and the application of solid mathematical methods. Soon after, deep learning proved to be a breakthrough technology, eclipsing all other methods. The transformer architecture debuted in 2017 and was used to produce impressive generative AI applications, amongst other use cases.\n",
      "Investment in AI boomed in the 2020s. The recent AI boom, initiated by the development of transformer architecture, led to the rapid scaling and public releases of large language models (LLMs) like ChatGPT. These models exhibit human-like traits of knowledge, attention, and creativity, and have been integrated into various sectors, fueling exponential investment in AI. However, concerns about the potential risks and ethical implications of advanced AI have also emerged, causing debate about the future of AI and its impact on society.\n",
      "\n",
      "\n",
      "== Precursors ==\n",
      "\n",
      "\n",
      "=== Mythical, fictional, and speculative precursors ===\n",
      "\n",
      "\n",
      "==== Myth and legend ====\n",
      "In Greek mythology, Talos was a creature made of bronze who acted as guardian for the island of Crete. He would throw boulders at the ships of invaders and would complete 3 circuits around the island's perimeter daily. According to pseudo-Apollodorus' Bibliotheke, Hephaestus forged Talos with the aid of a cyclops and presented the automaton as a gift to Minos. In the Argonautica, Jason and the Argonauts defeated Talos by removing a plug near his foot, causing the vital ichor to flow out from his body and rendering him lifeless.\n",
      "Pygmalion was a legendary king and sculptor of Greek mythology, famously represented in Ovid's Metamorphoses. In the 10th book of Ovid's narrative poem, Pygmalion becomes disgusted with women when he witnesses the way in which the Propoetides prostitute themselves. Despite this, he makes offerings at the temple of Venus asking the goddess to bring to him a woman just like a statue he carved.\n",
      "\n",
      "\n",
      "==== Medieval legends of artificial beings ====\n",
      "\n",
      "In Of the Nature of Things, the Swiss alchemist Paracelsus describes a procedure that he claims can fabricate an \"artificial man\". By placing the \"sperm of a man\" in horse dung, and feeding it the \"Arcanum of Mans blood\" after 40 days, the concoction will become a living infant.\n",
      "The ear..\n"
     ]
    }
   ],
   "source": [
    "for i,doc in enumerate(docs):\n",
    "    print(f\"--------Result{i+1}---------\")\n",
    "    print(f\"Content:\\n {doc.page_content}..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb1d1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26f439f9",
   "metadata": {},
   "source": [
    "## `Vector Store Retrivers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2aeeed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bab59e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Your source documents\n",
    "documents = [\n",
    "    Document(page_content=\"LangChain helps developers build LLM applications easily.\"),\n",
    "    Document(page_content=\"Chroma is a vector database optimized for LLM-based search.\"),\n",
    "    Document(page_content=\"Embeddings convert text into high-dimensional vectors.\"),\n",
    "    Document(page_content=\"OpenAI provides powerful embedding models.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "135c73d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "embeddings=OpenAIEmbeddings()\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"new_collection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e86b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = vector_store.as_retriever(search_kwargs={\"k\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "830b6b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "query='What is Chroma used for?'\n",
    "results = retriver.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c413d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Chroma is a vector database optimized for LLM-based search.'),\n",
       " Document(metadata={}, page_content='LangChain helps developers build LLM applications easily.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73c1b7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------Result1-------------\n",
      "Chroma is a vector database optimized for LLM-based search.\n",
      "\n",
      "-------------Result2-------------\n",
      "LangChain helps developers build LLM applications easily.\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n-------------Result{i+1}-------------\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87be5d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search(query,k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7718dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------1-------------\n",
      "Chroma is a vector database optimized for LLM-based search.\n",
      "-----------2-------------\n",
      "LangChain helps developers build LLM applications easily.\n"
     ]
    }
   ],
   "source": [
    "for i,doc in enumerate(results):\n",
    "    print(f\"-----------{i+1}-------------\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ec20e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
